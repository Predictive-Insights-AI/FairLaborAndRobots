<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# Make a new resume for this position:

Profile insights
Here’s how the job qualifications align with your profile.
Skills

Prompt engineering
(Required)

Kubernetes
(Required)

Generative AI
(Required)

+ show more

Do you have experience in Prompt engineering?
Education

Bachelor's degree
(Required)

Master's degree
(Required)
 
Job details
Here’s how the job details align with your profile.
Pay

\$100,960 - \$151,440 a year
Job type

Full-time
 
Location
Estimated commute
60 minutes from 129 king st
Job address
Hartford, CT 06112•Hybrid work
 
Full job description

24%
Resume Match
5 of 21 keywords
Simplify
Data Engineer - GE08AE
We’re determined to make a difference and are proud to be an insurance company that goes well beyond coverages and policies. Working here means having every opportunity to achieve your goals – and to help others accomplish theirs, too. Join our team as we help shape the future.

We are seeking a talented and motivated AI Data Engineer to join our innovative team. The ideal candidate will have strong expertise in generative AI technologies, experience in implementing AI pipelines, and knowledge of vector and graph databases. We're looking for someone with hands-on experience in prompt engineering, unstructured data processing, and agentic workflow implementation. As a Senior AI Data Engineer, you will contribute to the development of advanced AI systems that leverage state-of-the-art generative models, implement efficient RAG (Retrieval-Augmented Generation) architectures, and integrate with our data infrastructure. Familiarity with Snowflake integration and insurance industry use cases is a plus.

This role will have a Hybrid work schedule, with the expectation of working in an office location (Hartford, CT; Chicago, IL; Columbus, OH; and Charlotte, NC) 3 days a week (Tuesday through Thursday).

Primary Job Responsibilities

Design, develop, and implement complex data pipelines for AI/ML, including those supporting RAG architectures, using technologies such as Python, Snowflake, AWS, GCP, and Vertex AI.
Implement end-to-end generative AI pipelines, from data ingestion to pipeline deployment and monitoring.
Build and maintain data pipelines that ingest, transform, and load data from various sources (structured, unstructured, and semi-structured) into data warehouses, data lakes, vector databases (e.g., Pinecone, Weaviate, Faiss - consider specifying which ones you use or are exploring), and graph databases (e.g., Neo4j, Amazon Neptune - same consideration as above).
Develop and implement data quality checks, validation processes, and monitoring solutions to ensure data accuracy, consistency, and reliability.
Implement end-to-end generative AI data pipelines, from data ingestion to pipeline deployment and monitoring.
Develop complex AI systems, adhering to best practices in software engineering and AI development.
Work with cross-functional teams to integrate AI solutions into existing products and services.
Keep up-to-date with AI advancements and apply new technologies and methodologies to our systems.
Implement and optimize RAG architectures and pipelines.
Develop solutions for handling unstructured data in AI pipelines.
Implement agentic workflows for autonomous AI systems.
Develop graph database solutions for complex data relationships in AI systems.
Integrate AI pipelines with Snowflake data warehouse for efficient data processing and storage.
Apply GenAI solutions to insurance-specific use cases and challenges.
Required Qualifications:

Candidates must be authorized to work in the US without company sponsorship. The company will not support the STEM OPT I-983 Training Plan endorsement for this position.
Bachelor's or Master's degree in Computer Science, Artificial Intelligence, or a related field.
3+ years of experience in data engineering, with at least 2 years focused on generative AI technologies.
Strong experience in implementing production-ready enterprise-grade GenAI pipelines.
Experience with prompt engineering techniques for large language models.
Experience in implementing Retrieval-Augmented Generation (RAG) pipelines, integrating retrieval mechanisms with language models.
Knowledge of vector databases and graph databases, including implementation and optimization.
Experience in processing and leveraging unstructured data for GenAI applications.
Proficiency in implementing agentic workflows for AI systems.
Strong programming skills in Python and familiarity with deep learning frameworks such as PyTorch or TensorFlow.
Proficiency in implementing scalable agentic workflows for AI systems. (AWS (Lambda, S3, EC2, SageMaker) , Langchain, Langgraph etc. or GCP Vertex AI , embedding, chunking and grounding strategies)
Experience in vector databases, graph databases, NoSQL, Document DBs , including design, implementation, and optimization. (e.g. AWS open search or GCP Vertex AI, neo4j etc. Mongo, Dynamo etc.)
Experience with cloud platforms (AWS, GCP, or Azure) and containerization technologies (Docker, Kubernetes).
Good communication skills and ability to explain technical concepts to various stakeholders.
Preferred Qualifications:

Experience in multi cloud hybrid AI solutions.
Experience with Open search, Vector stores/search, Vertex AI and Graph db.
Experience in building/designing autonomous AI agents
Knowledge of natural language processing (NLP) and computer vision technologies.
Contributions to open-source AI projects or research publications in the field of generative AI.
Compensation

The listed annualized base pay range is primarily based on analysis of similar positions in the external market. Actual base pay could vary and may be above or below the listed range based on factors including but not limited to performance, proficiency and demonstration of competencies required for the role. The base pay is just one component of The Hartford’s total compensation package for employees. Other rewards may include short-term or annual bonuses, long-term incentives, and on-the-spot recognition. The annualized base pay range for this role is:

\$100,960 - \$151,440

Certainly! Here’s a resume tailored for the **AI Data Engineer – Generative AI, RAG, Prompt Engineering, Kubernetes** role in Hartford, CT. This version emphasizes your experience with generative AI, prompt engineering, unstructured data, cloud, vector/graph DBs, and relevant insurance/industry use cases.

---

# [Your Name]

Deerfield, MA | [Your Email] | [Your Phone] | [LinkedIn URL]

---

## Professional Summary

Innovative AI Data Engineer with over 6 years of experience building scalable data and AI solutions for enterprises in insurance, healthcare, and technology. Proven expertise in generative AI, prompt engineering, RAG (Retrieval-Augmented Generation), Kubernetes, cloud orchestration, vector/graph databases, and unstructured data pipelines. Adept at deploying production-grade AI/ML systems, automating workflows, and leading complex data engineering projects. Holds bachelor’s and master’s degrees in mathematics and data science.

---

## Core Skills

- **Prompt Engineering for LLMs**
- **Generative AI \& RAG Architectures**
- Kubernetes \& Docker
- Python (Pandas, PyTorch, TensorFlow)
- Vertex AI, AWS (S3, Lambda, SageMaker, Athena)
- Data Pipelines (ETL/ELT)
- Vector Databases (Pinecone, Weaviate, Faiss)
- Graph Databases (Neo4j, Amazon Neptune)
- Unstructured Data Processing
- Agentic Workflow Implementation (LangChain, LangGraph)
- Snowflake Integration
- Data Quality \& Validation
- Cloud Platforms: AWS, GCP, Azure
- Communication \& Cross-Functional Collaboration

---

## Professional Experience

### Product Developer (Independent Contractor)

**Self-Employed** | July 2024 – Present

- Engineered AI pipelines using AWS Activate, Couchbase, and Auth0 for secure, scalable SaaS products.
- Integrated cloud databases and established prompt engineering workflows for generative LLM prototypes.
- Developed end-to-end solutions for startup clients, including unstructured data processing and API integrations.


### Data Analyst (via Harvey Nash)

**Expedia Group** | Nov 2022 – Nov 2023

- Built and optimized large-scale data pipelines (600TB+) for regulatory and business analytics in cloud environments.
- Used prompt engineering and Github Copilot to accelerate Python-based ETL and data QA, enabling rapid compliance reporting.
- Developed RAG pipeline prototypes by integrating external APIs, automated address validation, and retrieval systems for global data governance.
- Created dynamic Tableau dashboards and Python data visualizations for real-time executive decision-making.
- Worked with JSON, XML, and unstructured data to deliver compliance datasets; collaborated with RegOps, data science, and engineering teams using agile practices.
- Enhanced query performance by 50% through distributed computing and advanced data pipeline design.


### Founder \& CEO / AI Product \& Data Science Lead

**PassMyExam LLC (ExamPA.net)** | Nov 2019 – May 2022

- Designed and deployed AI-driven education technology using simulated insurance claim data, serving 15,000+ users.
- Generated artificial datasets for insurance using Monte Carlo, supporting predictive analytics and RAG use cases.
- Built automated ETL, cross-validation, clustering, and statistical reporting pipelines using Python, SQL, and cloud tools.
- Managed full-stack deployments and led product strategy for launching new AI features, including LLM-based virtual tutors.


### Data Science Consultant

**BeyondMCB** | Nov 2021 – Feb 2022

- Developed a centralized data warehouse and reporting for manufacturing/logistics, transforming siloed unstructured data into actionable analytics.
- Implemented data ingestion workflows and correlation analyses on geospatial accident data.


### Data Scientist

**Boehringer Ingelheim (via DataScience Talent Limited)** | Jul 2021 – Sep 2021

- Built ETL pipelines for e-commerce and pharmaceutical analytics on AWS; reverse-engineered GLMs with Python and SQL.
- Participated in agile team sprints, using Jupyter Notebooks for exploratory analysis and model validation.


### Data Scientist

**Keywell.AI** | Sep 2020 – Jun 2021

- Designed EHR data pipelines using AWS Glue, Athena, and S3 to enable self-service AI dashboards for healthcare teams.
- Refactored complex SQL scripts, improving performance and maintainability of AI-driven reporting systems.


### Predictive Modeler

**Milliman Intellicript** | Jan 2019 – Apr 2020

- Engineered production-ready predictive modeling and data pipeline monitoring for underwriting risk scores, leveraging Python, R, and SQL.
- Built automated model reporting dashboards to track drift/decay, used by leading health insurers.
- Won first place in SOA Predictive Analytics Research Contest for innovation in model explainability (quantile regression for GBM).

---

## Education

**Master of Science in Data Science** (if applicable, or list as "Graduate-level coursework in AI/ML")
**Bachelor of Science in Mathematics, Summa Cum Laude**
University of Massachusetts Amherst | GPA: 3.90

---

## Technical Certifications

- Society of Actuaries: PA, STAM, IFM, FM, P
- AWS Activate Startups Program

---

## Selected Achievements

- Reduced data pipeline costs 50% by optimizing distributed architectures and implementing advanced data validation.
- Designed GenAI datasets for 14+ insurance use cases, validated by 300+ clients.
- Delivered cloud-native AI/ML pipelines and dashboards adopted by Fortune 500 clients in insurance and healthcare.

---

## Technical Proficiencies

**Languages \& Frameworks:** Python, R, SQL, PyTorch, TensorFlow, PowerShell
**AI/ML \& GenAI:** Prompt Engineering, LLMs, RAG, Agentic Workflows, Monte Carlo Simulation
**DevOps \& Cloud:** AWS (S3, Lambda, SageMaker, Glue, Athena), GCP (Vertex AI), Docker, Kubernetes
**Databases:** Snowflake, Pinecone, Weaviate, Faiss, Neo4j, Amazon Neptune, SQL Server, MongoDB, DynamoDB
**Visualization:** Tableau, Power BI, Excel, D3.js
**Workflow:** Git, Jira, Agile/Scrum

---

## Publications \& Awards

- First Place, SOA Predictive Analytics Research Contest – Quantile Regression for Gradient Boosting
- [List any relevant open-source or AI/GenAI contributions/publications if applicable]

---

## Additional

- U.S. Citizen | Available for hybrid work (Hartford, CT)
- Excellent communication; experienced in cross-functional collaboration and client engagement

---

**References available upon request**

---

**Instructions for .docx:**
Copy the above into Microsoft Word, apply formatting as desired, and save as .docx. Let me know if you want a pre-formatted Word template or edits for your specific master's degree/education details!
<span style="display:none">[^1]</span>

<div align="center">⁂</div>

[^1]: MASTER-RESUME.docx

